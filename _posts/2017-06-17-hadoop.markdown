---
layout: post
title:  "hadoop!!!"
date:   2017-06-17 09:41:47 +0530
categories: hadoop 2.0
img: Hadoop2.0-ArchSummary.jpg
categories: [one, two]
---
Hadoop 2 Arch Summary Start.

## BigData 정의
- 기존 데이터베이스 관리도구의 능력을 넘어서는 대량(수십 테라바이트)의 정형 또는 심지어 데이터베이스 형태가 아닌 비정형의 데이터 집합조차 포함한 데이터로부터 가치를 추출하고 결과를 분석하는 기술이다.
- 빅 데이터는 큰 용량(volume), 빠른 속도(velocity), 그리고(또는) 높은 다양성(variety)을 갖는 정보 자산으로서 이를 통해 의사 결정 및 통찰 발견, 프로세스 최적화를 향상시키기 위해서는 새로운 형태의 처리 방식이 필요하다.

## Hadoop 개요
- 대량의 데이터를 처리하기 위한 `병렬 분산 처리 소프트웨어`
- 분산 파일 시스템과의 강한 연계를 통해, 높은 스루풋 처리를 실현하는 분산 처리 소프트웨어
- 자바(Java) 기반으로 개발되어 일반적인 서버에서 동작
- 서버를 추가하면 용량과 성능이 향상(스케일 아웃, Scale-out)
- 관계형 데이터베이스나 검색엔진과는 다름

## Hadoop 탄생
더그 커팅(Doug Cutting)을 중심으로 시작
![delete gh-pages branch]({{site.baseurl}}/images/hadoop-logo-2.gif)

## RDBMS와 Hadoop 비교
1. 다루는 데이터 크기
2. 데이터 조작
3. 응답 시간(Latency)
4. 서버 대수와 성능 향상
5. 데이터구조(구조화 데이터/준 구조화 데이터)

## Hadoop 아키텍쳐
1. HDFS : Hadoop 분산 파일 시스템
- HDFS의 편리성
- 확장성
- HDFS의 신뢰성
- 접근 패턴 제한

2. Hadoop MapReduce 프레임워크
- 여러 사람이 전표 처리를 하는 상황을 예로 들어본다.
- MapReduce 처리 흐름
 : Map 처리
 : Shuffle 처리
 : Reduce 처리
- 데이터 변경 관점에서 보는 MapReduce
